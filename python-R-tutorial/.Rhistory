abs_diff <- daily_spec %>%
filter(`Parameter Name` == param, `State Name` %in% states) %>%
summarize(mean = mean(na.rm = TRUE, `Arithmetic Mean`))
abs_diff
states <- c("California", "Arizona")
param <- "EC PM2.5 LC TOR"
abs_diff <- daily_spec %>%
filter(`Parameter Name` == param, `State Name` %in% states) %>%
group_by(`State Name`) %>%
summarize(mean = mean(na.rm = TRUE, `Arithmetic Mean`))
abs_diff
states <- c("California", "Arizona")
param <- "EC PM2.5 LC TOR"
abs_diff <- daily_spec %>%
filter(`Parameter Name` == param, `State Name` %in% states) %>%
group_by(`State Name`) %>%
summarize(mean = mean(na.rm = TRUE, `Arithmetic Mean`))
diff <- abs(abs_diff[`Arizona`] - abs_diff[`California`])
abs_diff[1]
abs_diff[1][1]
abs_diff$mean[1]
states <- c("California", "Arizona")
param <- "EC PM2.5 LC TOR"
abs_diff <- daily_spec %>%
filter(`Parameter Name` == param, `State Name` %in% states) %>%
group_by(`State Name`) %>%
summarize(mean = mean(na.rm = TRUE, `Arithmetic Mean`))
diff <- abs(abs_diff$mean[1] - abs_diff$mean[2])
diff
param <- "OC PM2.5 LC TOR"
med_level <- daily_spec %>%
filter(`Parameter Name` == param, `Longitude` < -100) %>%
summarize(median = median(na.rm = TRUE, `Arithmetic Mean`))
med_level
require("knitr")
opts_knit$set(root.dir = "~/Data-Analysis-Machine-Learning/")
library(tidyverse)
library(readxl)
aqs_sites <- read_excel("data-files/aqs_sites.xlsx")
# Get the site numbers
sites <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
rename("Site Num" = `Site Number`)
View(sites)
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(sites, by = c("State Num", "State Code",
"County Code"))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(sites, by = c("Site Num", "State Code",
"County Code"))
View(sites)
# Get the site numbers
sites <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
rename("Site Num" = `Site Number`) %>%
mutate(`Site Num` = as.numeric(`Site Num`))
View(sites)
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(sites, by = c("Site Num", "State Code",
"County Code"))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
right_join(sites, by = c("Site Num", "State Code",
"County Code"))
# Get the site numbers
sites <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
rename("Site Num" = `Site Number`) %>%
mutate(`Site Num` = as.character(`Site Num`))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
right_join(sites, by = c("Site Num", "State Code",
"County Code"))
# Get the site numbers
sites <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
rename("Site Num" = `Site Number`) %>%
mutate(`Site Num` = as.numeric(`Site Num`))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
right_join(sites, by = c("Site Num", "State Code",
"County Code"))
# Get the site numbers
sites <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
rename("Site Num" = `Site Number`) %>%
mutate(`Site Num` = as.character(`Site Num`)) %>%
mutate(`State Code` = as.character(`State Code`)) %>%
mutate(`County Code` = as.character(`County Code`)) %>%
# Get the site numbers
sites <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
rename("Site Num" = `Site Number`) %>%
mutate(`Site Num` = as.character(`Site Num`)) %>%
mutate(`State Code` = as.character(`State Code`)) %>%
mutate(`County Code` = as.character(`County Code`))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
right_join(sites, by = c("Site Num", "State Code",
"County Code"))
View(med_eastern_level)
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(sites, by = c("Site Num", "State Code",
"County Code"))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
right_join(sites, by = c("Site Num", "State Code",
"County Code"))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(sites, by = c("Site Num", "State Code",
"County Code"))
resi_suburban <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
summarize(n = n())
resi_suburban
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(aqs_sites, by = c("Site Num", "State Code",
"County Code"))
require("knitr")
opts_knit$set(root.dir = "~/Data-Analysis-Machine-Learning/")
library(readxl)
aqs_sites <- read_excel("data-files/aqs_sites.xlsx")
colnames(aqs_sites)
str(aqs_sites$`Land Use`)
str(aqs_sites$`Location Setting`)
resi_suburban <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
summarize(n = n())
library(tidyverse)
resi_suburban <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
summarize(n = n())
resi_suburban
# Join the two data sets
small_aqs <- head(aqs_sites, 3)
small_spec <- head(daily_spec, 4)
small_join <- left_join(small_spec, small_aqs, by = c("Latitude, Longitude"))
# Join the two data sets
small_aqs <- head(aqs_sites, 3)
small_spec <- head(daily_spec, 4)
small_join <- left_join(small_spec, small_aqs, by = c("Latitude", "Longitude"))
View(small_join)
# Join the two data sets
join <- left_join(daily_spec, aqs_sites, by = c("Latitude", "Longitude"))
# Join the two data sets
join <- left_join(daily_spec, aqs_sites, by = c("Latitude", "Longitude"))
View(join)
require("knitr")
opts_knit$set(root.dir = "~/Data-Analysis-Machine-Learning/")
library(tidyverse)
# Join the two data sets
param <- "EC PM2.5 LC TOR"
land_use <- "RESIDENTIAL"
location <- "SUBURBAN"
long <- -100
join <- left_join(daily_spec, aqs_sites, by = c("Latitude", "Longitude"))
med_level_eastern <- join %>%
filter(`Land Use` == land_use, `Location Setting` == location,
`Parameter Name` == param) %>%
summarize(median = median(`Arithmetic Mean`, na.rm = TRUE))
med_level
med_level_eastern <- join %>%
filter(`Land Use` == land_use, `Location Setting` == location,
`Parameter Name` == param, `Longitude` >= long) %>%
summarize(median = median(`Arithmetic Mean`, na.rm = TRUE))
med_level
med_level_eastern <- join %>%
filter(`Land Use` == land_use, `Location Setting` == location,
`Parameter Name` == param, `Longitude` >= long) %>%
summarize(median = median(`Arithmetic Mean`, na.rm = TRUE))
med_level_eastern
str(daily_spec$`Date Local`)
str(daily_spec$`Date Local`)
class(daily_spec$`Date Local`)
library(lubridate)
param <- "Sulfate PM2.5 LC"
land_use <- "COMMERCIAL"
comm_sulfate <- join %>%
filter(`Parameter Name` == param, `Land Use` == land_use) %>%
mutate(month = month(`Date Local`)) %>%
group_by(month) %>%
summarize(average_level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
arrange(desc(average_level))
head(comm_sulfate, 5)
california <- daily_spec %>%
filter(`State Code` == 6, `County Code` == 65, `Site Number` == 8001)
california <- daily_spec %>%
filter(`State Code` == 6, `County Code` == 65, `Site Num` == 8001)
View(california)
california <- daily_spec %>%
filter(`State Code` == 6, `County Code` == 65, `Site Num` == 8001)
View(daily_spec)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001")
View(california)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001") %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
View(california)
View(daily_spec)
california_state <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001")
View(california_state)
california_state <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001") %>%
mutate(day = day(`Date Local`), month = month(`Date Local`),
year = year(`Date Local`))
View(california_state)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001") %>%
mutate(day = day(`Date Local`), month = month(`Date Local`),
year = year(`Date Local`)) %>%
group_by(`Parameter Name`, year, month, day) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
View(california)
california_state <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
mutate(day = day(`Date Local`), month = month(`Date Local`),
year = year(`Date Local`))
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
mutate(day = day(`Date Local`), month = month(`Date Local`),
year = year(`Date Local`)) %>%
group_by(`Parameter Name`, year, month, day) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
cali_test <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `Date Local`) %>%
select(`State Code`, `County Code`, `Site Num`, `Date Local`, `Parameter Name`,
`Arithmetic Mean`) %>%
summarise(avg = mean(`Arithmetic Mean`, na.rm = TRUE))
#group_by(`Date Local`) %>%
#summarise(Total = sum(avg, na.rm = TRUE)) %>%
#filter(Total > 10)
View(cali_test)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
group_by(`Date Local`) %>%
summarize(total = sum(`level`))
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
group_by(`Date Local`) %>%
summarize(total = sum(`level`)) %>%
filter(total > 10) %>%
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
group_by(`Date Local`) %>%
summarize(total = sum(`level`)) %>%
filter(total > 10)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
group_by(`Date Local`) %>%
summarize(total = sum(`level`)) %>%
filter(total > 10) %>%
count()
View(california)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
View(corr)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level)
View(corr)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`,`Date Local`) %>%
summarize(correlation = cor("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC"))
View(corr)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`,`Date Local`) %>%
summarize(correlation = cor(`Sulfate PM2.5 LC`, `Total Nitrate PM2.5 LC`))
View(corr)
?cor
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`,`Date Local`) %>%
summarize(correlation = cor(`Sulfate PM2.5 LC`, `Total Nitrate PM2.5 LC`, na.rm = TRUE))
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`) %>%
summarize(correlation = cor(`Sulfate PM2.5 LC`, `Total Nitrate PM2.5 LC`))
View(corr)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`) %>%
summarize(correlation = cor(`Sulfate PM2.5 LC`, `Total Nitrate PM2.5 LC`)) %>%
arrange(desc(correlation))
View(corr)
head(corr, 5)
View(comm_sulfate)
ls()
rm(list = ls())
library(swirl)
swirl()
Sys.Date()
mean(c(2, 4, 5))
submit()
boring_function('My first function!')
boring_function
submit()
my_mean(c(4, 5, 10))
submit()
remainder(5)
remainder(11, 5)
remainder(divisor = 11, num = 5)
remainder(4, div = 2)
args(remainder)
submit()
evaluate(std, c(1.4, 3.6, 7.9, 8.8))
evaluate(std(), c(1.4, 3.6, 7.9, 8.8))
evaluate(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(function(x){x+1}, 6)
evaluate(function(x){x[1]}, c(8, 4, 0))
evaluate(function(x){x[len(x)]}, c(8, 4, 0))
evaluate(function(x){x[length(x)]}, c(8, 4, 0))
?paste
paste("Programming", "is", "fun!")
submit()
submit()
play()
telegram("Good", "Morning")
nxt()
skip()
telegram("Nishant", "Panda")
submit()
mad_libs(place = "NY", adjective = "great", noun = "panda")
submit()
('I' %p% 'love') %p% 'R!'
'I' %p% 'love' %p% 'R!'
setwd("~/Data-Analysis-Machine-Learning/python-R-tutorial")
library(purrr)
# map_chr
vec <- c(5,4,3,2,1)
map_chr(vec, function(x){
type <- c("one", "two", "three", "four", "five")
type[x]
})
vec <- 1:5
map_if(vec, function(x){
x %% 2 == 0
}, function(y){
y^2
})
# map_if returns a list, pipe it to unlist
vec <- 1:5
map_if(vec, function(x){
x %% 2 == 0
}, function(y){
y^2
}) %>% unlist()
# map_if returns a list, pipe it to unlist
vec <- 1:5
map_if(vec, function(x){
x %% 2 == 0
}, function(y){
y
}) %>% unlist()
# map_if returns a list, pipe it to unlist
vec <- 1:5
map_if(vec, function(x){
x %% 2 == 0
}, function(y){
y^2
}) %>% unlist()
# map_if returns a list, pipe it to unlist
# note how the function is applied only to even numbers, the rest of the data is left untouched
vec <- 1:5
map_if(vec, function(x){
x %% 2 == 0
}, function(y){
y^2
}) %>% unlist()
vec <- seq(100, 500, 100)
index <- c(1, 3, 5)
map_at(vec, index, function(x){
x - 10
}) %>% unlist()
map2_chr(letters, 1:26, paste)
pmap_chr(list(list(1,2,3),
list("one", "two", "three"),
list("un", "dos", "tres")),
paste)
pmap_chr(list(c(1,2,3),
c("one", "two", "three"),
c("un", "dos", "tres")),
paste)
pmap_chr(list(c(1,2,3),
c("one", "two", "three"),
c("un", "dos", "tres")),
paste)
pmap_chr(list(c(1,2,3),
c("one", "two", "three"),
c("un", "dos", "tres")),
paste)
reduce(letters[1:4], function(x,y){
paste0(x,y)
})
# combine d with c, then dc with b, then dcb with a.
reduce_right(letters[1:4], function(x,y){
paste0(x,y)
})
