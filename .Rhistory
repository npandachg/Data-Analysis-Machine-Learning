"County Code"))
# Get the site numbers
sites <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
rename("Site Num" = `Site Number`) %>%
mutate(`Site Num` = as.character(`Site Num`)) %>%
mutate(`State Code` = as.character(`State Code`)) %>%
mutate(`County Code` = as.character(`County Code`)) %>%
# Get the site numbers
sites <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
rename("Site Num" = `Site Number`) %>%
mutate(`Site Num` = as.character(`Site Num`)) %>%
mutate(`State Code` = as.character(`State Code`)) %>%
mutate(`County Code` = as.character(`County Code`))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
right_join(sites, by = c("Site Num", "State Code",
"County Code"))
View(med_eastern_level)
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(sites, by = c("Site Num", "State Code",
"County Code"))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
right_join(sites, by = c("Site Num", "State Code",
"County Code"))
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(sites, by = c("Site Num", "State Code",
"County Code"))
resi_suburban <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
summarize(n = n())
resi_suburban
param <- "EC PM2.5 LC TOR"
long <- -100
# Merge with sites
med_eastern_level <- daily_spec %>%
left_join(aqs_sites, by = c("Site Num", "State Code",
"County Code"))
require("knitr")
opts_knit$set(root.dir = "~/Data-Analysis-Machine-Learning/")
library(readxl)
aqs_sites <- read_excel("data-files/aqs_sites.xlsx")
colnames(aqs_sites)
str(aqs_sites$`Land Use`)
str(aqs_sites$`Location Setting`)
resi_suburban <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
summarize(n = n())
library(tidyverse)
resi_suburban <- aqs_sites %>%
filter(`Land Use` == "RESIDENTIAL",
`Location Setting` == "SUBURBAN") %>%
distinct(`Site Number`, `State Code`, `County Code`) %>%
summarize(n = n())
resi_suburban
# Join the two data sets
small_aqs <- head(aqs_sites, 3)
small_spec <- head(daily_spec, 4)
small_join <- left_join(small_spec, small_aqs, by = c("Latitude, Longitude"))
# Join the two data sets
small_aqs <- head(aqs_sites, 3)
small_spec <- head(daily_spec, 4)
small_join <- left_join(small_spec, small_aqs, by = c("Latitude", "Longitude"))
View(small_join)
# Join the two data sets
join <- left_join(daily_spec, aqs_sites, by = c("Latitude", "Longitude"))
# Join the two data sets
join <- left_join(daily_spec, aqs_sites, by = c("Latitude", "Longitude"))
View(join)
require("knitr")
opts_knit$set(root.dir = "~/Data-Analysis-Machine-Learning/")
library(tidyverse)
# Join the two data sets
param <- "EC PM2.5 LC TOR"
land_use <- "RESIDENTIAL"
location <- "SUBURBAN"
long <- -100
join <- left_join(daily_spec, aqs_sites, by = c("Latitude", "Longitude"))
med_level_eastern <- join %>%
filter(`Land Use` == land_use, `Location Setting` == location,
`Parameter Name` == param) %>%
summarize(median = median(`Arithmetic Mean`, na.rm = TRUE))
med_level
med_level_eastern <- join %>%
filter(`Land Use` == land_use, `Location Setting` == location,
`Parameter Name` == param, `Longitude` >= long) %>%
summarize(median = median(`Arithmetic Mean`, na.rm = TRUE))
med_level
med_level_eastern <- join %>%
filter(`Land Use` == land_use, `Location Setting` == location,
`Parameter Name` == param, `Longitude` >= long) %>%
summarize(median = median(`Arithmetic Mean`, na.rm = TRUE))
med_level_eastern
str(daily_spec$`Date Local`)
str(daily_spec$`Date Local`)
class(daily_spec$`Date Local`)
library(lubridate)
param <- "Sulfate PM2.5 LC"
land_use <- "COMMERCIAL"
comm_sulfate <- join %>%
filter(`Parameter Name` == param, `Land Use` == land_use) %>%
mutate(month = month(`Date Local`)) %>%
group_by(month) %>%
summarize(average_level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
arrange(desc(average_level))
head(comm_sulfate, 5)
california <- daily_spec %>%
filter(`State Code` == 6, `County Code` == 65, `Site Number` == 8001)
california <- daily_spec %>%
filter(`State Code` == 6, `County Code` == 65, `Site Num` == 8001)
View(california)
california <- daily_spec %>%
filter(`State Code` == 6, `County Code` == 65, `Site Num` == 8001)
View(daily_spec)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001")
View(california)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001") %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
View(california)
View(daily_spec)
california_state <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001")
View(california_state)
california_state <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001") %>%
mutate(day = day(`Date Local`), month = month(`Date Local`),
year = year(`Date Local`))
View(california_state)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001") %>%
mutate(day = day(`Date Local`), month = month(`Date Local`),
year = year(`Date Local`)) %>%
group_by(`Parameter Name`, year, month, day) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
View(california)
california_state <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
mutate(day = day(`Date Local`), month = month(`Date Local`),
year = year(`Date Local`))
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
mutate(day = day(`Date Local`), month = month(`Date Local`),
year = year(`Date Local`)) %>%
group_by(`Parameter Name`, year, month, day) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
cali_test <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `Date Local`) %>%
select(`State Code`, `County Code`, `Site Num`, `Date Local`, `Parameter Name`,
`Arithmetic Mean`) %>%
summarise(avg = mean(`Arithmetic Mean`, na.rm = TRUE))
#group_by(`Date Local`) %>%
#summarise(Total = sum(avg, na.rm = TRUE)) %>%
#filter(Total > 10)
View(cali_test)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
group_by(`Date Local`) %>%
summarize(total = sum(`level`))
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
group_by(`Date Local`) %>%
summarize(total = sum(`level`)) %>%
filter(total > 10) %>%
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
group_by(`Date Local`) %>%
summarize(total = sum(`level`)) %>%
filter(total > 10)
california <- daily_spec %>%
filter(`State Code` == "06", `County Code` == "065", `Site Num` == "8001",
`Parameter Name` %in% c("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC")) %>%
#mutate(day = day(`Date Local`), month = month(`Date Local`),
#year = year(`Date Local`)) %>%
group_by(`Parameter Name`, `Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
group_by(`Date Local`) %>%
summarize(total = sum(`level`)) %>%
filter(total > 10) %>%
count()
View(california)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE))
View(corr)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level)
View(corr)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`,`Date Local`) %>%
summarize(correlation = cor("Sulfate PM2.5 LC", "Total Nitrate PM2.5 LC"))
View(corr)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`,`Date Local`) %>%
summarize(correlation = cor(`Sulfate PM2.5 LC`, `Total Nitrate PM2.5 LC`))
View(corr)
?cor
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`,`Date Local`) %>%
summarize(correlation = cor(`Sulfate PM2.5 LC`, `Total Nitrate PM2.5 LC`, na.rm = TRUE))
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`) %>%
summarize(correlation = cor(`Sulfate PM2.5 LC`, `Total Nitrate PM2.5 LC`))
View(corr)
corr <- daily_spec %>%
filter(`Parameter Name`  %in% c("Sulfate PM2.5 LC",
"Total Nitrate PM2.5 LC")) %>%
group_by(`Parameter Name`, `State Code`, `County Code`, `Site Num`,
`Date Local`) %>%
summarize(level = mean(`Arithmetic Mean`, na.rm = TRUE)) %>%
spread(`Parameter Name`, level) %>%
group_by(`State Code`, `County Code`, `Site Num`) %>%
summarize(correlation = cor(`Sulfate PM2.5 LC`, `Total Nitrate PM2.5 LC`)) %>%
arrange(desc(correlation))
View(corr)
head(corr, 5)
View(comm_sulfate)
ls()
rm(list = ls())
library(swirl)
install_course("Advanced R Programming")
swirl()
?seq_len
library(readr)
library(dplyr)
## Download data from RStudio (if we haven't already)
if(!file.exists("data/2016-07-20.csv.gz")) {
download.file("http://cran-logs.rstudio.com/2016/2016-07-20.csv.gz",
"data/2016-07-20.csv.gz")
}
cran <- read_csv("data/2016-07-20.csv.gz", col_types = "ccicccccci")
cran %>% filter(package == "filehash") %>% nrow
download.file("http://cran-logs.rstudio.com/2016/2016-07-20.csv.gz",
"data/2016-07-20.csv.gz")
install_github()
devtools::install_github()
install.packages("devtools")
devtools::install_github("metacran/cranlogs")
cranlogs::cran_downloads(when = "last-year", packages = "filehash")
cranlogs::cran_downloads(when = "last-month", packages = "filehash")
getwd()
setwd("~/Data-Analysis-Machine-Learning")
?sprintf()
date <- "2016-07-20"
year <- substr(date, 1, 4)
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz",
year, date)
src
basename(src)
?basename
file.path("data-files/data", basename(src))
library(dplyr)
library(readr)
# check function downloads from cran-logs of rstudio
## pkgname: package name (character)
## date: YYYY-MM-DD (character)
num_download <- function(pkgname, date){
# get the year from the date
year <- substr(data, 1, 4)
# get the file location : "http://cran-logs.rstudio.com/YYYY/YYYY-MM-DD.csv.gz"
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year, date)
# construct path for storing local file
setwd("~/Data-Analysis-Machine-Learning/")
dest <- file.path("data-files/", basename(src))
# download the file if it doesn't already exist
if(!file.exists(dest)) download.file(src, dest, quiet = TRUE)
cran <- read_csv(dest, col_types = "ccicccccci", progress = FALSE)
cran %>% filter(package == pkgname) %>% nrow
}
num_download("filehash", "2017-01-20")
library(dplyr)
library(readr)
# check function downloads from cran-logs of rstudio
## pkgname: package name (character)
## date: YYYY-MM-DD (character)
num_download <- function(pkgname, date){
# get the year from the date
year <- substr(date, 1, 4)
# get the file location : "http://cran-logs.rstudio.com/YYYY/YYYY-MM-DD.csv.gz"
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year, date)
# construct path for storing local file
setwd("~/Data-Analysis-Machine-Learning/")
dest <- file.path("data-files/", basename(src))
# download the file if it doesn't already exist
if(!file.exists(dest)) download.file(src, dest, quiet = TRUE)
cran <- read_csv(dest, col_types = "ccicccccci", progress = FALSE)
cran %>% filter(package == pkgname) %>% nrow
}
num_download("filehash", "2017-01-20")
num_download("ggplot2")
library(dplyr)
library(readr)
# check number of downloads of cran package on a given date from cran-logs of rstudio. Default date is Jan 1st 2017
## pkgname: package name (character)
## date: YYYY-MM-DD (character)
num_download <- function(pkgname, date = "2017-01-01"){
# get the year from the date
year <- substr(date, 1, 4)
# get the file location : "http://cran-logs.rstudio.com/YYYY/YYYY-MM-DD.csv.gz"
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year, date)
# construct path for storing local file
setwd("~/Data-Analysis-Machine-Learning/")
dest <- file.path("data-files/", basename(src))
# download the file if it doesn't already exist
if(!file.exists(dest)) download.file(src, dest, quiet = TRUE)
cran <- read_csv(dest, col_types = "ccicccccci", progress = FALSE)
cran %>% filter(package == pkgname) %>% nrow
}
num_download("ggplot2")
num_download("filehash", "2017-01-20")
num_download("filehash", "2017-01-20")
num_download("ggplot2")
num_download("ggplot2")
# write a function that checks for dependent packages and downloads it
check_dependency <- function(){
if (!require(dplyr)) {
message("Installing dplyr")
install.packages("dplyr")
}
if (!require(readr)) {
message("Installing readr")
install.packages("readr")
}
}
#library(dplyr)
#library(readr)
# check number of downloads of cran package on a given date from cran-logs of rstudio. Default date is Jan 1st 2017
## pkgname: package name (character)
## date: YYYY-MM-DD (character)
num_download <- function(pkgname, date = "2017-01-01"){
# get the year from the date
year <- substr(date, 1, 4)
# get the file location : "http://cran-logs.rstudio.com/YYYY/YYYY-MM-DD.csv.gz"
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year, date)
# construct path for storing local file
setwd("~/Data-Analysis-Machine-Learning/")
dest <- file.path("data-files/", basename(src))
# download the file if it doesn't already exist
if(!file.exists(dest)) download.file(src, dest, quiet = TRUE)
cran <- read_csv(dest, col_types = "ccicccccci", progress = FALSE)
cran %>% filter(package == pkgname) %>% nrow
}
num_download("filehash", "2017-01-20")
num_download("ggplot2")
#library(dplyr)
#library(readr)
# check number of downloads of cran package on a given date from cran-logs of rstudio. Default date is Jan 1st 2017
## pkgname: package name (character)
## date: YYYY-MM-DD (character)
num_download <- function(pkgname, date = "2017-01-01"){
check_dependency()
# get the year from the date
year <- substr(date, 1, 4)
# get the file location : "http://cran-logs.rstudio.com/YYYY/YYYY-MM-DD.csv.gz"
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year, date)
# construct path for storing local file
setwd("~/Data-Analysis-Machine-Learning/")
dest <- file.path("data-files/", basename(src))
# download the file if it doesn't already exist
if(!file.exists(dest)) download.file(src, dest, quiet = TRUE)
cran <- read_csv(dest, col_types = "ccicccccci", progress = FALSE)
cran %>% filter(package == pkgname) %>% nrow
}
num_download("filehash", "2017-01-20")
num_download("ggplot2")
# Vectorize the num_download function to have a vector of arguments in pkgname
## pkgname: package name (vector of character)
## date: YYYY-MM-DD (character)
num_download2 <- function(pkgname, date = "2017-01-01"){
check_dependency()
# get the year from the date
year <- substr(date, 1, 4)
# get the file location : "http://cran-logs.rstudio.com/YYYY/YYYY-MM-DD.csv.gz"
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year, date)
# construct path for storing local file
setwd("~/Data-Analysis-Machine-Learning/")
dest <- file.path("data-files/", basename(src))
# download the file if it doesn't already exist
if(!file.exists(dest)) download.file(src, dest, quiet = TRUE)
cran <- read_csv(dest, col_types = "ccicccccci", progress = FALSE)
cran %>% filter(package %in% pkgname) %>%
group_by(package) %>%
summarize(n = n())
}
num_download2(c("ggplot2", "dplyr"))
num_download2(c("ggplot2", "dplyr"))
# Vectorize the num_download function to have a vector of arguments in pkgname
## pkgname: package name (vector of character)
## date: YYYY-MM-DD (character)
num_download2 <- function(pkgname, date = "2017-01-01"){
check_dependency()
# get the year from the date
year <- substr(date, 1, 4)
# get the file location : "http://cran-logs.rstudio.com/YYYY/YYYY-MM-DD.csv.gz"
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year, date)
# construct path for storing local file
setwd("~/Data-Analysis-Machine-Learning/")
dest <- file.path("data-files/", basename(src))
# download the file if it doesn't already exist
if(!file.exists(dest)) download.file(src, dest, quiet = TRUE)
cran <- read_csv(dest, col_types = "ccicccccci", progress = FALSE)
cran %>% filter(package %in% pkgname) %>%
group_by(package) %>%
summarize(number_downloads = n())
}
num_download2(c("ggplot2", "dplyr"))
# Vectorize the num_download function to have a vector of arguments in pkgname
## pkgname: package name (vector of character)
## date: YYYY-MM-DD (character)
num_download2 <- function(pkgname, date = "2017-01-01"){
check_dependency()
# check arguments
if(!is.character(pkgname)) stop("pkgname should be character(vector) ")
if(!is.character(date)) stop("date should be a character")
if(length(date) != 1) stop("date should be a single length character")
# get the year from the date
year <- substr(date, 1, 4)
# get the file location : "http://cran-logs.rstudio.com/YYYY/YYYY-MM-DD.csv.gz"
src <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year, date)
# construct path for storing local file
setwd("~/Data-Analysis-Machine-Learning/")
dest <- file.path("data-files/", basename(src))
# download the file if it doesn't already exist
if(!file.exists(dest)) download.file(src, dest, quiet = TRUE)
cran <- read_csv(dest, col_types = "ccicccccci", progress = FALSE)
cran %>% filter(package %in% pkgname) %>%
group_by(package) %>%
summarize(number_downloads = n())
}
num_download2(10)
num_download2("ggplot2")
num_download2(10)
